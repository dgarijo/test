Title: Utilising Semantic Web Ontologies to publish Experimental Workflows

This paper describes a tool for documenting and finding workflows associated to scientific experiments, allowing authors to specify the license of all the components (software, datasets and workflow specification itself) that have been involved with the workflow somehow.

The paper is relevant for the call for linked research, and shares some good ideas related to reuse and publication of workflows. For example, I like the idea of forking workflows from other scientists and receive automatically credit for reproducing their work, as well as being able to associate different types of licenses to the different components associated to the workflow.

That said, I think the paper presents some issues too. I list them below:
1) I found it hard to understant the contribution by the authors. While the title talks about workflow publishing, the introduction state that the goal is to "investigate means to discern the parity between adoption of workflows as a documentation mechanism and determining how researchers carry out research documentation and the associated challenges in augmenting existing publication mechanisms using linked open data principles". Then, in section 3 a tool for documenting workflows is presented. My question is: what is the problem? Workflow publishing (i.e., providing the means to make all the resources associated to the experiment public and accessible), workflow documentation (i.e., adding metadata on the workflow steps) or determining the challenges in the documentation process (i.e., capturing requirements by users).

2) The paper presents a lot of related work on Section 2, which takes almost half of the paper, but I don't a clear the connection from most of it to the work presented in Section 3. The approach presented by the authors does not ensure reproducibility of the workflows, so why talk about all those efforts for workflow reproducibility, reuse, discovery and even fragment mining? 
More generally, why is the work in Section 2 not enough for addressing the problem the authors want to address? How does the tool proposed help users in that regard?

3) I could not access the questionaire link. I could access the tool, but I got a 404 when creating a new workflow, and executing and forking workflow tabs are blank. 

4) I am curious about the execution task. Does this mean that users use the documentation tool for executing a workflow (therefore becoming a sort of workflow system) or that users use a workflow system to execute the workflow, and then fill in the template as a lab notebook. If that is the case, most workflow systems already have the means to track provenance records. Why would they use the documentation tool to fill in the details of an execution?

5) I also found confusing the way in which the tool was tested. Forking a workflow makes sense when you know you want to reuse it for a purpose. Just telling users to fork a workflow and modify something doesn't seem very useful if there is no motivation behind.

6) How many users have participated in the evaluation of the tool? Where are pointers to the results? What is their opinion regarding the usefulness of this approach?

7) The names used for the parameters and inputs on the figures in the paper are not meaningful. How am I supposed to look for a workflow with data variable d2?

8) What does it mean to "translate to ODRL"?